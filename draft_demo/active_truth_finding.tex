% Active Ensembling for Truth Finding
\section{Active Ensembling for Truth Finding}
We describe in this section our use of active ensembling in the context of truth finding
for discovering gradually the optimal set of algorithms that together maximizes the accuracy
of the process when users' feedbacks arrive into the system.

\subsection{Ensembling }
\begin{itemize}
\item donner idée générale pour introduire  ce qu'est l'ensembling
\item on a besoin de le faire dans le contexte de truth discovery car aucune methode ne bat toutes les autres dans tous les cas de figure
\item donc on combine les methodes : il y plusieurs façon de combiner par ex. consensus de méthodes, etc.
\item expliquer quelles méthodes on combine avec leurs avantages et inconvénients
\end{itemize}


Ensembling, or commonly ensemble-based active learning, is a semi-supervised learning method that learns
about an appropriate combinaison of multiple classifier types for a given task by interactively querying users (or other types of sources)
for \emph{labeled examples}. 

In our setting, we are interesting on discovering the optimal combinaison among several possible truth finding algorithms
which correspond to our classifier types.
This combinaison is excepted to maximize the precision of the truth finding process on claims outputted by TextRunner as 
possible answers with respect to a user's query about a given real-world fact.
A well known lack, e.g., see in~\cite{Li12, Wagui14}, of existing truth discovering algorithms is that they are mostly sensitive
to given application domains and data characteristics. As a consequence, there is no approach that outperforms the others on all 
types of datasets. Furthermore, the truth finding process is harder in practical scenarios in the sense that there exists usually 
no labeled examples, or \emph{ground truth data}, against which one can evaluate the precision of the different algorithms in order to choose
the more accurate one on data of interest.  Fortunately, however, human being has often a certain knowledge background about certain real world facts.
The user knowledge is a valuable source of labeled examples that should be harnessed as partial standard for evaluating the accuracy of our truth finding 
process. Indeed, even though a partial ground truth data could be obtained from the users, an optimal truth finding strategy change over time as we obtain
more data from sources, for instance when claims are continuously extracted from Web sources by TextRunner.
To tackle the aformentionned lacks of exsisting truth finding algorithms, in particular in real applications such as information extracted systems, 
we will use an ensembling in truth finding in order to continuously discover an optimal hybrid truth finding approach when the extractor is gradually
queried and users' feedbacks arrive. As we shall show later, we will actively involve users for labeled example in our ensemble-based learning process.

Several query strategies, e.g., uncertainty sampling or query by committee, could be adopted in order to obtain from users labeled
examples for the active learning process; see~\cite{burr12} for more details about active learning. In this study, we have used query 
by committee approach which is proven to be very effective in many different settings.



Our ensemble-based active learning is performed by considering twelve well established truth finding algorithms which range from naive approaches
to sophisticated ones. We briefly introduce each considered class of truth disc in the following.

\begin{enumerate}
 \item Naive techniques: The class is essentially formed by \emph{majority voting} which considers the truth as providing the majority of 
sources. This class assumes that the sources are equally reliable.
 \item Iterative techniques
 \item EM based techniques
 \item Dependency detection based techniques
\end{enumerate}



\subsection{Active Learning Strategy}
\begin{itemize}
 \item notre approche que l'on défend ici dans la démo est  semi supervisée en impliquant de l'utiliseur de façon active
en lui demandant s'il peut confirmer des faits (facts)
\item si on a une ground truth partielle on la "rejoue" cas par cas
\end{itemize}

