% Active Ensembling for Truth Finding
\section{Active Ensembling for Truth Finding}
We describe in this section our use of active ensembling in the context of truth finding
for discovering gradually the optimal set of algorithms that together maximizes the accuracy
of the process when users' feedbacks arrive into the system.

\subsection{Ensembling }
\begin{itemize}
\item donner idée générale pour introduire  ce qu'est l'ensembling
\item on a besoin de le faire dans le contexte de truth discovery car aucune methode ne bat toutes les autres dans tous les cas de figure
\item donc on combine les methodes : il y plusieurs façon de combiner par ex. consensus de méthodes, etc.
\item expliquer quelles méthodes on combine avec leurs avantages et inconvénients
\end{itemize}

\medskip

Ensembling, or commonly ensemble-based active learning, is a semi-supervised learning method that learns
about an appropriate combinaison of multiple classifier types for a given task by interactively querying 
users (or other types of sources) for \emph{labeled examples}. 

In our setting, we are interesting on discovering the optimal combinaison among several possible truth finding algorithms
which correspond to our classifier types.
This combinaison is excepted to maximize the precision of the truth finding process on claims outputted by TextRunner as 
possible answers with respect to a user's query about a given real-world fact.
A well known lack, e.g., as shown in~\cite{Li12, Wagui14}, of existing truth discovering algorithms is that they are mostly sensitive
to particular application domains and data characteristics. As a consequence, there is no approach that outperforms the others on all 
types of datasets. Furthermore, the truth finding process is harder in practical scenarios in the sense that there usually exists
no labeled examples, or \emph{ground truth data}, against which one can evaluate the precision of the different algorithms in order to choose
the more accurate one on data of interest.  Fortunately, however, human being has often a certain knowledge background about certain real world facts.
The user knowledge is a valuable source of labeled examples that should be harnessed as partial standard for evaluating the accuracy of our truth finding 
process. Indeed, even though a partial ground truth data could be obtained from the users, an optimal truth finding strategy change over time as we obtain
more data from sources, for instance when claims are continuously extracted from Web sources by TextRunner.
To tackle the aformentionned lacks of exsisting truth finding algorithms, especially in real applications like information extracted systems, 
we will use an active ensembling in truth finding in order to continuously discover an optimal hybrid truth finding approach when the extractor is gradually
queried and users' feedbacks arrive. As we shall show later, we will actively involve users for labeled example in our ensemble-based learning process.

Determining the optimal sample of unlabeled items to send to the sources, e.g., users, for labels during an active learning problem is a challenging problem.
Several query strategies, e.g., uncertainty sampling or query by committee, or Support vector machine (SVM) models have been proposed for the definition of such a optimal sample of data. Note that 
the type of the selected data along with the size of the sample are crucial for the effectiveness of the learning procedure; we defer to~\cite{burr12} for more details about active machine learning. 
In this study, we have used query by committee strategy in which an ensemble of hypotheses is learned and examples that cause maximum disagreement amongst this
committee (with respect to the predicted truth) are selected as the most informative. 
points for which the ``committee" disagree. Query by committee is known to be efficient for finding an optimal set of ensemble methods using active learning.

\lamine{J'ai juste mentionn\'e ``query by committee" in guise d'exemple. La strat\'egie utilis\'ee doit \^etre choisie.}


We use and compare twelve well established truth finding algorithms in the literature,
which we cluster in different classes according to their specificities.
We briefly present each class of considered truth discovering algorithms in the following.

\begin{enumerate}
 \item \textbf{Iterative techniques:} TruthFinder~\cite{YinHY08}, Cosine, 2-Estimates and 3-Estimates~\cite{GallandAMS10}, 
 AccuNoDep~\cite{DongBS09}
 \item \textbf{EM based techniques:} MLE~\cite{WangKLA12}, LTM~\cite{ZhaoRGH12}, SimpleLCA and GuessLCA~\cite{PasternackR13}
 \item \textbf{Dependency detection based techniques:} Depen, Accu, and AccuSim~\cite{DongBS09}
\end{enumerate}

\lamine{La classification des algorithmes est juste une proposition. Peut \^etre qu'il existe 
une meilleure classification.}


\subsection{Active Learning Process}
\begin{itemize}
 \item notre approche que l'on défend ici dans la démo est  semi supervisée en impliquant de l'utilisateur de façon active
en lui demandant s'il peut confirmer des faits (facts)
\item si on a une ground truth partielle on la "rejoue" cas par cas
\end{itemize}

\medskip

We rely on an ensemble-based semi-supervised learning process for discovering an hybrid, i.e., an optimal ensemble of truth
finding algorithms for information extraction systems. Let denote by $\qset$ the set of successive user queries processed 
by the information extraction system. For each query $\query$ in $\qset$ about the fact $\fact{\query}$ we have the corresponding
sets of claims $\claimset_{\query}$ returned by the extractor. We refer to the entire set of all claims by $\claimset$ regarding $\qset$.
We assume that $\claimset$ contains labeled and unlabeled claims where labeled claims, corresponding to our partial ground truth, are those 
for which we  know whether they are correct or not by querying the user. In contrast, we do not know yet the truth about unlabeled claims and
would like to discover by using the best ensemble of truth finding algorithms. We refer respectively to labeled and unlabeled set of claims by 
$\claimset^{\mathsf{L}}$ and $\claimset^{\mathsf{U}}$. Given a base learning algorithm $\mathsf{X}$, a number $k$ of fixed act iterations, and 
a fixed size $m$ of a sampling, we perform ensembling on our set of truth finding algorithms as follows.

\begin{enumerate}
 \item We first select a committee of classifiers (here, truth finding techniques) using 
 our base learning algorithm and the labeled claims $\claimset^{\mathsf{L}}$.
 \item We then discover the true values for unlabeled claims in $\claimset^{\mathsf{U}}$
 using the chosen committee
 \item We select a subset $\mathsf{T}$ of
 $m$ true claims 
 \item We request labels for these claims to the user (our oracle here).
 \item We lastly remove claims in $\mathsf{T}$ from $\claimset$ and them to $\claimset^{\mathsf{L}}$.
\end{enumerate}

We repeat the process above $k$ times and we return the ensemble at the end.
