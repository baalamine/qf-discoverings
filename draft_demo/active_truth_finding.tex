% Active Ensembling for Truth Finding
\section{Ensembling for Truth Finding}\label{ensembling}
We present in this section an adaptive truth finding approach which uses active ensembling in order to 
adaptively learn about an optimal set of truth finding algorithms that outperforms any individual
technique on any given dataset. Our learning approach will actively involve users for knowing the correct
labels (or answers) about some queries which cause a large disagreement regarding the predictions of the algorithms.

\subsection{Ensemble-Based Active Learning}
\begin{itemize}
\item donner idée générale pour introduire  ce qu'est l'ensembling
\item on a besoin de le faire dans le contexte de truth discovery car aucune methode ne bat toutes les autres dans tous les cas de figure
\item donc on combine les methodes : il y plusieurs façon de combiner par ex. consensus de méthodes, etc.
\item expliquer quelles méthodes on combine avec leurs avantages et inconvénients
\end{itemize}

\medskip
An ensemble-based active learning, or commonly ensembling, is a semi-supervised learning approach that tries
to figure out an optimal ensemble of classifiers for a given classification process by actively querying an 
oracle, e.g., a human being, about the labels of a sample of data items. Ensembling, thereby, enables to perform
classification consistently well across datasets without having to determine a \emph{priori} a suitable classifier 
type.

In our context, the truth finding algorithms correspond to our set of classifiers. The underlying \emph{binary classification} 
task consists of discovery the correct truth label of a set of claims about given user queries. Indeed, a truth finding 
algorithm is formally a mapping $\textsf{TF}:~\claimset \mapsto \{\TRUE, \FALSE\}$ which associates each claim in $\claimset$
to $\TRUE$ or $\FALSE$. A good truth finding algorithm provides  predictions that are close to the actual world. Unfortunately, 
a well known property, e.g., as shown in~\cite{Li12, Wagui14}, of existing truth discovering algorithms is their specificity to 
certain application domains or datasets. As a consequence, there is no actual approach that outperforms the others on all types 
of datasets. On the other hand, truth finding is hard in practical scenarios because there is often no prior knowledge guiding to
the selection beforehand of an optimal algorithm, in particular when the context is dynamic. More importantly, a large set of labeled 
examples (or ground truth) for evaluating the precisions of the algorithms is expensive to obtain in real applications. 

In general, human being has a certain background knowledge about some real-world facts. Such a knowledge can serve as a valuable and inexpensive source of labels for a 
rather reasonable number of data items. However, having this partial ground truth from users is not sufficient in order to definitively decide about an optimal truth
finding strategy because it can change over time as we obtain more details from sources, e.g. when claims are continuously extracted by TextRunner in order to answer new 
queries. Therefore, there is a need for an adaptive approach able to dynamically figure out the optimal truth finding process when users' feedbacks and new knowledge about 
the world are available. We believe that active ensembling should be helpful to this end.

We further propose an approach that combines truth discovery and open information extraction with ensemble-based active learning for adaptively learning about the optimal 
ensemble of truth finding algorithms when the OpenIE system is gradually querying and labeled examples from users are available.
As we shall show later, we will actively involve users to obtain the truth about a sample of particular facts in the learning process. The way this sampling is defined and
chosen is crucial for the effectiveness of the active learning. Several sample selection strategies, e.g., random sampling, query by committee, or support vector machine models,
have been proposed for the definition of the type of selected data items along the size of the sample; we defer to~\cite{burr12} for more details about active machine learning.
In this study, we use \emph{query by committee} (QBC) for ensemble-based active learning. In QBC, an ensemble of hypotheses is learned and examples that cause maximum disagreement amongst this committee (with respect to the predicted truth) are selected as the 
most informative. 
%points for which the ``committee" disagree. 
%Query by committee is known to be a very effective active learning approach that has been successfully applied to different 
%classification problems.

\lamine{Peut \^etre qu'il y a mieux que QBC ?}

We use and compare twelve well established truth finding algorithms in the literature,
which we cluster in different classes according to their specificities.
We briefly present each class of considered truth discovering algorithms in the following.

\begin{enumerate}
 \item \textbf{Iterative techniques:} TruthFinder~\cite{YinHY08}, Cosine, 2-Estimates and 3-Estimates~\cite{GallandAMS10}, 
 AccuNoDep~\cite{DongBS09}
 \item \textbf{EM based techniques:} MLE~\cite{WangKLA12}, LTM~\cite{ZhaoRGH12}, SimpleLCA and GuessLCA~\cite{PasternackR13}
 \item \textbf{Dependency detection based techniques:} Depen, Accu, and AccuSim~\cite{DongBS09}
\end{enumerate}

\lamine{La classification des algorithmes est juste une proposition. Peut \^etre qu'il existe 
une meilleure classification.}


\subsection{Our Active Learning Strategie}
\begin{itemize}
 \item notre approche que l'on défend ici dans la démo est  semi supervisée en impliquant de l'utilisateur de façon active
en lui demandant s'il peut confirmer des faits (facts)
\item si on a une ground truth partielle on la "rejoue" cas par cas
\end{itemize}

\medskip

We rely on an ensemble-based semi-supervised learning process for discovering an hybrid, i.e., an optimal ensemble of truth
finding algorithms for information extraction systems. Let denote by $\qset$ the set of successive user queries processed 
by the information extraction system. For each query $\query$ in $\qset$ about the fact $\fact{\query}$ we have the corresponding
sets of claims $\claimset_{\query}$ returned by the extractor. We refer to the entire set of all claims by $\claimset$ regarding $\qset$.
We assume that $\claimset$ contains labeled and unlabeled claims where labeled claims, corresponding to our partial ground truth, are those 
for which we  know whether they are correct or not by querying the user. In contrast, we do not know yet the truth about unlabeled claims and
would like to discover by using the best ensemble of truth finding algorithms. We refer respectively to labeled and unlabeled set of claims by 
$\claimset^{\mathsf{L}}$ and $\claimset^{\mathsf{U}}$. Given a base learning algorithm $\mathsf{X}$, a number $k$ of fixed act iterations, and 
a fixed size $m$ of a sampling, we perform truhth finding with ensembling on our set of truth finding algorithms as follows.

\begin{enumerate}
 \item We first train our ensemble of truth finding algorithms (representing here our set of classifiers)  on the current set of labeled claims
 $\claimset^{\mathsf{L}}$ \lamine{How the base learning algorithm should be implemented?}
 \item We then pass our set of unlabeled claims in $\claimset^{\mathsf{U}}$ to the ensemble of truth finding algorithms
 \item Each algorithm in the current ensemble predicts the label of each claim
 \item The claims that induce the most label prediction disagreement are queried for their labels and added to the training set
 \item We select a subset $\mathsf{T}$ of the $m$ claims that induce the most label prediction disagreement
 \item We request the labels of these $m$ claims to the user 
 \item We lastly remove claims in $\mathsf{T}$ from $\claimset$ and add them together with their acquired truth labels to $\claimset^{\mathsf{L}}$.
\end{enumerate}

We repeat the process above $k$ times or until the ensemble meets some pre-defined criteria, e.g. when the size of the ensemble
reaches a certain pre-defined value. At the end of the active learning process, the prediction, i.e., truth discovery, is made 
by taking the majority vote of the resulting ensemble members. 
