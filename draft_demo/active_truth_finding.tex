% Active Ensembling for Truth Finding
\section{Ensembling for Truth Finding}\label{ensembling}
We present in this section an adaptive truth finding approach which uses active ensembling in order to 
adaptively learn about an optimal set of truth finding algorithms that outperforms any individual
technique on any given dataset. Our learning approach will actively involve users for the correct
labels (or answers) of a sample of queries that cause maximal disagreement amongst our classifiers.

\subsection{Ensemble-Based Active Learning}
\begin{itemize}
\item donner idée générale pour introduire  ce qu'est l'ensembling
\item on a besoin de le faire dans le contexte de truth discovery car aucune methode ne bat toutes les autres dans tous les cas de figure
\item donc on combine les methodes : il y plusieurs façon de combiner par ex. consensus de méthodes, etc.
\item expliquer quelles méthodes on combine avec leurs avantages et inconvénients
\end{itemize}

\medskip
An ensemble-based active learning, or commonly ensembling, is a semi-supervised learning approach that tries
to figure out an optimal ensemble of classifiers for a given classification problem by actively querying an 
oracle, e.g., a human being, about the labels of a sample of data items. Ensembling, thereby, enables to perform
classification consistently well across datasets without having to determine a \emph{priori} a suitable classifier 
type.

In our context, the truth finding algorithms correspond to our set of classifiers. The underlying \emph{binary classification} 
problem consists of assigning the correct truth label to a set of claims about given user queries. Indeed, a truth finding 
algorithm is formally a mapping $\textsf{TF}:~\claimset \mapsto \{\TRUE, \FALSE\}$ which associates to each claim in $\claimset$
either $\TRUE$ or $\FALSE$. A good truth finding algorithm provides  predictions that are close to the actual world. Unfortunately, 
a well known property, e.g., as shown in~\cite{Li12, Wagui14}, of existing truth discovering algorithms remains their sentivity
to certain application domains or datasets. As a consequence, there is no actual approach that outperforms the others on all types 
of datasets. On the other hand, truth finding is hard in practical scenarios because there is often no prior knowledge guiding to
the selection, beforehand, of an optimal algorithm, in particular when the context is dynamic. More importantly, a large set of labeled 
examples (or ground truth) for evaluating the precisions of the algorithms is expensive to obtain in real applications. 

In general, human being has a certain background knowledge about some real-world facts. Such a knowledge can serve as a valuable and inexpensive source of labels for a 
rather reasonable number of data items. However, having this partial ground truth from users is not sufficient in order to definitively decide about an optimal truth
finding strategy because it can change over time as we obtain more information from sources, e.g. when claims are continuously extracted by TextRunner for answering
new incoming queries. Therefore, there is a need for an adaptive approach able to dynamically figure out the optimal truth finding strategy when users' feedbacks and 
new knowledge about the world are available. We believe that active ensembling should be helpful to this end.

We put forward and demonstrate an approach which combines truth discovery and open information extraction with ensemble-based active learning for adaptively learning about the optimal 
ensemble of truth finding algorithms when the OpenIE system is gradually querying and labeled examples from users are available.
As we shall show later, we will actively involve users to obtain the truth about a sample of particular facts during the learning process. The way this sampling is defined and
chosen is crucial for the effectiveness of the active learning. Several sample selection strategies, e.g., random sampling, query by committee, or support vector machine models,
have been proposed for the definition of the type of selected data items along the size of the sample; we defer to~\cite{burr12} for more details about active machine learning.
In this study, we use \emph{query by committee} (QBC) for ensemble-based active learning. QBC states that the best data items to select for labels are those that cause 
the \emph{maximal disagreement} among the predictions of an ensemble of diverse but partially accurate classifiers during active learning. Furthermore, we seek to provide
an adaptive active learning by looking for an optimal ensemble given a larger set of input classifiers.
\lamine{Peut \^etre qu'il y a mieux que QBC ?}

To learn about an optimal ensemble from a diverse set of classifiers, we have considered
twelve well established truth finding algorithms in the literature, having three different types 
according to their specificities. Note that diversity offers better result in active learning than
using homogenoeus classifiers (see~\cite{Lu15}). We briefly present each considered class of truth
discovering algorithms in the following.

\begin{enumerate}
 \item \textbf{Iterative techniques:} TruthFinder~\cite{YinHY08}, Cosine, 2-Estimates and 3-Estimates~\cite{GallandAMS10}, 
 AccuNoDep~\cite{DongBS09}
 \item \textbf{EM based techniques:} MLE~\cite{WangKLA12}, LTM~\cite{ZhaoRGH12}, SimpleLCA and GuessLCA~\cite{PasternackR13}
 \item \textbf{Dependency detection based techniques:} Depen, Accu, and AccuSim~\cite{DongBS09}
\end{enumerate}

\lamine{Peut \^etre qu'il existe une meilleure classification ?}


\subsection{Truth Finding with Active Ensembling}
\begin{itemize}
 \item notre approche que l'on défend ici dans la démo est  semi supervisée en impliquant de l'utilisateur de façon active
en lui demandant s'il peut confirmer des faits (facts)
\item si on a une ground truth partielle on la "rejoue" cas par cas
\end{itemize}

\medskip

We introduce an adaptive truth finding approach using active ensembling in order to discover an hybrid, i.e., an optimal
ensemble of truth finding algorithms, on which we could efficiently tells the truth for the output of OpenIE systems.
Our approach first searches for the optimal subset of truth finding algorithms using active ensembling and then it 
tells the truth by \emph{majority voting} on the predictions of the obtained ensemble. As we detail below, we follow the intuition
the adaptive strategy, proposed in~\cite{Lu15}, using QBC in order to perform active ensemble over our set of heterogeneous 
ensembles of truth finding algorithms. Such a strategy efficiently finds an optimal ensemble with the best ratio of classifier
types and the smallest size using \emph{random search} on a given search space.
\lamine{Adaptative ou non-adaptative apprentissage active?}


As a consequence and similarly to~\cite{Lu15}, we rely on an iterative active ensembling process which considers the set of claims $\claimset{}$, 
a training set of labeled claims $\claimset_{TR}$, testing set of claims $\claimset_{GT}$, an ensemble of truth finding algorithms, an adaptation
set which is used for adapting the configuration of the ensemble, a  and a stopping criteria (e.g., a predefined number of iterations or accuracy changes
between two iterations). At each iteration, the algorithm chooses exactly one set of claims about the same query for asking their labels to the user. Once
these labels are acquired from the user, the algorithm  adds the claims along with their truth labels into the training set, adapts the ensemble of truth 
finding algorithms for an optimal one, discards the old one and trains the new ensemble against the actual training set. We detail the learning procedure below.
\lamine{Une esquisse du process d'apprentissage active}

\begin{enumerate}
\item The algorithm starts with an \emph{initialization phase} initial initial values of parameters are set, an initial training set and ensemble of truth finding
algorithm are defined. Such an ensemble is trained on this initial training set.
 \item The algorithm pursues by giving the claims in $\claimset{}$ to the truth finding algorithm in the current ensemble for label predictions and then 
 it records the vote entropy of each query, thereby the underlying fact, according to the predictions of the committee.
 \item It chooses the set of claims associated to the query having the maximum vote entropy for label querying
 \item The set of acquired truth labels, together with the corresponding claims, are added into the training set and then discarded from $\claimset{}$.
 \item At this stage the algorithm uses an \emph{adaptation procedure} in order to tune the ensemble of truth finding algorithm towards an optimal one.
 \item The newly generated ensemble is trained on the updated training set of labeled claims.
\end{enumerate}

The steps 2--6 of the active learning algorithm are repeated until the stop criteria is satisfied. 
At the end of the active learning process, the truth discovery is finally realized by performing 
a majority vote on the predictions of the final inferred ensemble. 

\lamine{Esquisse de la m\'ethode d'adaptation}
In the adaptive phase of the learning, the algorithm tries to determine the optimal ensemble of 
truth finding algorithms which will guarantee the highest prediction accuracy  at the end. To do
so, we assume that our algorithm starts with an initial ensemble including one algorithm from each class.
At each iteration, the adaptive process creates variants of the current ensemble by discarding one algorithm
from the ensemble. 
