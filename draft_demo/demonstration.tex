\section{Our Demonstration System}\label{demonstration}
We describe in this section our system for 
combining truth discovring and information
extraction with active ensembling using the procedure described
in the previous sections. We first 
present the architecture of our system by
giving its different modules. Then, we provide
a typical demonstration scenario of a user interacting
with our system.


% Architecture and GUI
\subsection{System Components}
The architecture of our demonstration system, given in
Figure~\ref{system_architecture}, comprises the following
five main components.

% User I/O Interface
\paragraph*{User Interface}
The user interface is the main component that enables a given user 
to interact with our system. Via the user interface component, 
one has the ability to provide a query (or a key phrase), to
recieve answers from the truth finding module or  label requests
from the active ensembling module. When a label request is sent 
is sent to the user, she (or he) also provides his answers through 
this component.


% Information extraction module
\paragraph*{OpenIE component} OpenIE is responsible to the extraction 
of information from the Web. It considers, as an input, a user query and queries
several Web corpus in order to returns the relevant set of candidate answers. Our
OpenIE component relies on TextRunner engine for the extraction of the set of candidate
Web claims with respect to a user query about a given real-world fact.

% Learning module
\paragraph*{Active Ensembling Module} This is the core component of our system which discovers
an optimal ensemble for truth finding over candidate claims extracted with the OpenIE 
component. The active ensembling module, as described in Section~3, evaluates set of twelves
truth finding algorithms on unlabeled claims, figures out the most controversal claims, and requests
labels from the user. Once it obtained feebacks from the user, it estimates the accuracy of the competing
algorithms on the labeled claims, and finally decides about the best one to use for each set of claims related 
to the same query or fact. The module returns an ensemble since one can have distinct good truth finding techniques
for various sets of claims about different facts.

% Truth finding engine
\paragraph*{Truth Finding Module} It corresponds to AllegatorTrack which contains
twelve truth finding algorithms with different accuracy according to the types of 
claims and the characteristics of sources.



% knwoledge bases
\paragraph*{Storage Module}The knowledge base contains the information used for the learning
phase the truth finding procedure. These information include the true facts for some relations
which have been learnt based on the feedbacks of the users. In addition, our knowledge base could
be enriched with ground truth about some facts from reliable sources such as Wikipedia. Based on 
the knowledge base, our system has the ability to improve the accuracy of the truth finding process
by learning about the best method to use or the best parameters, e.g., sources' accuracy scores, to 
consider for a better boostrapping of the process.

\begin{figure}[ht]
\begin{tikzpicture}[auto, line/.style ={draw,  thick, shorten <=0pt}]
  \matrix[matrix of nodes, row sep=5ex, column sep=1em] (mx) {
    User I/O Interface &\\
    IE Module &  Truth Finding Module\\
    & Ensembling Module\\ 
    & Storage Module (labeled claims)\\
  };
  %\node[ou=(mx-1-3)] (empty) {};
  \node[ou=(mx-2-1)] (oi) {};
  \node[ou=(mx-2-2)] (tf) {};
  \node[ou=(mx-3-2)] (lm) {};
  \node[ou=(mx-4-2)] (kb) {};
  %{[->, thick]
  %\draw(mx-1-1)edge(empty);
  %}
  {[->, thick]
  \draw(mx-1-1)edge(oi);
  \draw(oi)edge(tf);
  }
  {[<->]
    \draw(tf)edge(lm);
     \draw(lm)edge(kb);
  }
  \begin{scope}[every path/.style=line, <-]
   \path(mx-1-1)  - | (tf);
  % \path(mx-1-3)  - | (lm);
  \end{scope}

\end{tikzpicture}
\caption{Architecture of our system}\label{system_architecture}
\end{figure}
% Demonstration scenario
\subsection{Demonstration scenario}
A given user that wants to interact with our system
must do it through the search form. Through the search
form, she (or he) provides her searched relation, e.g.,
``Where is born Barack Obama?".
The searched relation is then 
passed to the information extraction engine,  TextRunner system
in our case, which returns a set of answers considered to be 
relevant for the user's request. Each claim in the returned list is
processed in order to extract the corresponding sources along a detailed
description of the claim which we format in a certain manner. The 
set of sources and the formatted versions of all claims are then passed
to the truth finding module which integrate all the claims and compute the
most probable answer together with the reliability scores of participated 
sources for the searched relation. Finally, the output of the truth finding
process is returned to the user. The user can also want to review the output
of our system by definitively validiting it or not through its knwoledge of the
modeled world. For example when the system has totally wrong, it may be interesting
to get such a kind of feedbacks from the user in order to change the used method, as
there are many available with our system, and to enhance the process for the further 
search about the same world. The user gives feedbacks using the option buttons on the 
left-hand side of the outputted claims or the text form. The feebacks given by the user
is saved in knwoledge bases within our system for further processes.
