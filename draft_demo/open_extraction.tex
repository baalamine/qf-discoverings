% Information Extraction Technique
\selectlanguage{english}
\section{Open Information Extraction}
\begin{itemize}
 \item décrire le type d'information auquel on s'intéresse par exemple "factoid claim"
 \item decrire le systeme sur lequel on se base
 \item décrire comment on transforme l'output de OpenIE
 \item donner qq exemples
\end{itemize}


In this study, we are interested on truth discovering on the large number of ``factoid" statements
(or claims) made by multiple Web sources in the same real-world domain. A ``factoid" claim , e.g., 
\emph{Barack Obama was born in Kenya}, is
a piece of unverified or inaccurate information that is presented as factual, often
as part of a publicity effort. Such type of claims  is usually accepted as true  because of its
frequent redundancy over multiple sources. We focus on conflicting factoid claims provided by typical 
open Web information extraction systems as answers to users' queries. Concretly, given user input, 
we retrieve the set of candidates claims, together with the associated sources, returned by TextRunner~\footnote{TextRunner is an online
at \href{http://openie.allenai.org/}{http://openie.allenai.org/}}
from a Web corpus. We then format this output in such a way that fits our truth discovering process.



% OIE Input and Ouput
\paragraph*{Data collection} We analyze claims about real-world facts
from TextRunner.
TextRunner is an open Web information extraction system relying
on an unsupervised extraction process on a Web corpus of unstructured textual
data. For more efficiency, it performs a single data-driven pass on 
this corpus and then extracts a list of candidate relational tuples 
which might reply a user input query about a given fact. In TextRunner, 
a user input query is typically a set of keywords
consisting  of two real-world \emph{entities} and a \emph{relation}. Such
a user input query $\query$ can be defined formally as a triplet $(\e{1}, \rel{}, \e{2})$
where $\e{1}$ and $\e{2}$ are real-world entities and $\rel{}$ is a relation. The argument $\rel{}$ 
specifies a possible relationship that might exist between the two given entities. None of the three 
arguments is mandatory, meaning that some of them can be not specified by the user when issuing 
his query. This captures the fact the user has a partial knowledge about the real world, which is 
common in practice. Let denote the fact the user input query $\query$ is referred to by $\fact{\query}$. 
TextRunner will find and extract a collection of Web claims related to this fact.

TextRunner's output is thus a set of candidate claims about a specific real-world fact.
This output is ranked by the system according to the number of sources that supports each
claim. A claim in this context can correspond to a tuple, a relation, or an real-world entity 
with respect to the given keywords. TextRunner also offers the ability, through Web hyperlinks, 
to access to the meta-data, e.g., the source, the type, the full corpus, etc., associated to each 
returned claim for further xploration. 
%We would harness these pointers in order to format the result obtained from the extraction system  in such the way that it 
%fits the input of our differents truth finding algorithms. We show in the following how such a formatting is realized.

\paragraph*{Data formatting}
Given a user input tuple $\query=(\e{1}, \rel{},\e{2})$, we refer to the
set of $n$ claims $\claim{1}\ldots \claim{n}$ extracted and returned by the
extration engine as potential answers. 
We assume that the query admits only one true answers, thereby we are in the presence of
$n$ conflicting answers. For each returned claim, we go through the linked pointer and extract the
corresponding source by using hand-written mapping rule. We denote the set of $m$ sources queried by 
the extraction system in order to answer $\query$ by $\source{1}, \ldots, \source{m}$.