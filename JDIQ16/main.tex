% v2-acmsmall-sample.tex, dated March 6 2012
% This is a sample file for ACM small trim journals
%
% Compilation using 'acmsmall.cls' - version 1.3 (March 2012), Aptara Inc.
% (c) 2010 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex latex
%
% For tracking purposes => this is v1.3 - March 2012

\documentclass[prodmode,acmtecs]{acmsmall} % Aptara syntax

% Package to generate and customize Algorithm as per ACM style
%\usepackage{mathptm}
\usepackage[pdfborder={0 0 0}]{hyperref}
\usepackage[ruled]{algorithm2e}
\usepackage{csquotes}
\usepackage{paralist}
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

% Metadata Information
\acmVolume{6}
\acmNumber{6}
\acmArticle{6}
\acmYear{2015}
\acmMonth{1}

% Document starts
\begin{document}

% HEADERS
\markboth{L. Berti-Equille and M. L. BA}{Actionable Truth Discovery Challenges}
% TITLE
\title{Actionable Truth Discovery Challenges}
% AUTHORS AND AFFILIATION
\author{LAURE BERTI-EQUILLE, MOUHAMADOU LAMINE BA
\affil{Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar}
}

\category{H.3.3}{Information Storage and Retrieval}{Information Search and Retrieval}
\category{H.2.0}{Database Management}{General}
\terms{Algorithms, Management, Verification}
\keywords{Truth Discovery, Fact-checking, Data Quality, Data Fusion, Information Extraction}
\acmformat{Laure Berti-Equille, Mouhamadou Lamine Ba,  2015. Actionable Truth Discovery Challenges.}


\begin{bottomstuff}
Author's address: L. Berti-Equille, M. L. Ba, Qatar Computing Research Institute(Current address), Hamad
Bin Khalifa University, Tornado Tower 18th, P.O. Box 5825, Doha, Qatar.
\end{bottomstuff}

\maketitle


\section{Introduction}
As online user-generated content grows exponentially, the reliance on Web data and information from social 
networking is growing in many domains for various private and corporate usages. 
One of the fundamental difficulties is that data can be biased, noisy, outdated, incorrect, misleading and
thus unreliable. Massive data from multiple sources amplifies this problem since conflicting information
have to be \textquote{aligned}, compared  and check to estimate their veracity. Obviously, truth discovery from 
the Web has significant practical importance: online rumor propagation~\cite{rumor-icdm2013}, mis- or disinformation
can have tremendous impacts on our society, economy, politics, and homeland security. Online fact-checkers (e.g., FactCheck
-- \url{http://www.factcheck.org/}) and humanitarian initiatives~\cite{ImranECDM13} have rapidly emerged as unavoidable for 
classifying and verifying (semi-automatically) online information. Beyond social media and computational journalism, the truth
discovery problem, intellectually and technically exciting enough, has been also widely studied in both the artificial intelligence
and the database communities, sometimes under the names of  \textquote{fact-checking}~\cite{GoasdoueKKLMZ13}, \textquote{information 
trustworthiness}~\cite{Thirunarayan2014182}, \textquote{information credibility}~\cite{PasternackR13}, or \textquote{information corroboration}~\cite{GallandAMS10}. 



Given a set of assertions from multiple sources, the ultimate goal of truth discovery is to correctly predict the truth label of the claimed
data items and compute sources' reliability with no \emph{a-priori} knowledge about the truthfulness of the assertions and the sources. One 
major line of previous work, which relaxes this assumption, extended fact-finding models with prior knowledge either about the assertions~\cite{PasternackR13} 
or about the source reputation via trust assessment~\cite{BalakrishnanK11}. Another line of research aimed at iteratively computing and updating the trustworthiness
of a source as a belief function in its claims, and then the belief score of each claim as a function of the trustworthiness its sources~\cite{YinHY08}, with 
probabilistic models which incorporate domain-specific aspects like source dependence~\cite{DongBHS10a}, evolving truth~\cite{DongBS09a}, hardness of certain 
claims~\cite{GallandAMS10}, or complex data structures~\cite{ZhaoRGH12,GoasdoueKKLMZ13}. However, current models suffer from various drawbacks that 
%restrictive assumptions, opacity, complex model settings, and lack of scalability, 
limit their usability to the wide diversity of Web information and realistic scenarios where knowing the truth as soon as possible 
is critical. 
 We argue that the next-generation data-sharing systems need to manage not only heterogeneity but also unreliable 
 information from various channels, in different languages, formats, and at different paces. Truth discovery systems 
 have to be set up to help institutions and citizens by providing rigorous, scientific explanations and reports 
 of their findings and collected evidences. Although some initial work towards such a vision,
 e.g., \cite{DongS2013,DongBHS10a,LiDLMS12}, there is still a need for a more fundamental paradigm shift in data
 management to address the truth discovery problem natively. Formally, this goes beyond adding layers and extensions to
 data fusion heuristics, data provenance or truth discovery models. Technically, the challenges are not only to  design 
 techniques and prototypes of truth discovery systems but also to democratize operational tools for Web scale \emph{information
 triage} and veracity verification.
  
  
  

 
%\vspace{-0.1cm}
% ****************** ARCHITECTURE ****************************************
\section{Actionable Truth Discovery Challenges}~\label{sect:challenges-solutions}
We present a set of research actionable challenges that together aim at effectively address 
the truth discovery problem in real-world over-information scenarios. We also briefly highlight
our vision of a preliminary solution.

\paragraph*{Timely and Actionable Truth Discovery} 
Discovering truth from past events and historical data is certainty useful, but
from a humanitarian perspective, actionable truth discovery from quasi real-time data 
could save lives. As a consequence, information extraction and triage as well as actionable
truth discovery computation need to be streamlined, prioritized,  and adjusted to the level 
of emergency and incompleteness of available information regarding the communities that will 
use it. This important usage-driven aspect goes beyond consistency checking and constraints.
%

\paragraph*{Data Alignment Across Languages, Formats, and Channels} 
Agility of a truth discovery system is of utmost importance both at 
the technical, structural, and semantic levels. 
Agility is the ability of the system 
to efficiently extract and map information: 
\begin{inparaenum}[(i)]
\item from various languages;
\item various formats and data structures; and
\item supported by various media and technologies.
\end{inparaenum}
For instance, actual information extraction applications (e.g., Open-Calais -- \url{http://www.opencalais.com})  
are often specific to a single channel/application/language and cannot be considered as \textquote{agile}. Moreover,
each step of textual content analysis produces systematic and random errors that 
require to be considered in truth discovery unlike previous attempts like~\cite{GoasdoueKKLMZ13}). 
Tracing and estimating  the errors of data extraction, formatting, and linking
is one of the main challenges for automating truth discovery. 
%

\paragraph*{Incomplete and Biased Observations}  
Observation data may be incomplete and biased for various 
reasons, e.g., security and privacy concerns, format limitations, and 
(unspecified) inferred values, leading to a truth discovery context where Open World
Assumption must hold. Modeling the data provider's/observer's is crucial since online 
sources have  various levels of {\it a priori} knowledge about the observation data 
collection technique, opportunistic data are {\it biased by  observation effort}, and the underlying
observation method is unknown. In addition, information may also suffer from \emph{observer's bias} and
\emph{disclosure bias}. One challenge is thus to estimate the incompleteness and biases and take them into
account in the truth discovery computation.

\paragraph*{Decontextualization and Distortion}  
When a piece of information is extracted from its original 
content and channel, it may lose its context along with important 
\textquote{semantic markers} that explain \emph{when, where, how, why,} and
\emph{for which purpose/audience} it has been produced.
Information without context can be easily distorted and misinterpreted.  
Moreover, the pace has to be considered when information  updates from Twitter, Facebook, and 
Wikipedia have to be \emph{aligned} with considering the source granularity (i.e., an
individual, an organization, a company, a government, etc.). 
Despites much research effort~\cite{eps270829} in formalizing contexts and rich context representation,
current information extraction  methods constrain the context representation and can usually not handle
a wide, unpredictable range of topics. Ultimately, all meta-information about the context and sources' 
characteristics have to be encoded as evidences and analyzed for truth discovery computation.

\paragraph*{Source Expertise and Information Correlation} 

In many domains, some sources are more authoritative or specialized, providing
accurate information for a small subset of real-world objects, while other
sources are generalist with a wider coverage, providing a huge amount of information,
some of which may be out-of-date or imprecise. Determining truth between such sources
based only on majority voting and similarity of values can easily lead to erroneous conclusions.
Hence, any approach for determining truth needs to consider the possibility that sources have different 
levels of expertise, various updating policies, and they provide different coverages of information over time.
Moreover, similar values across many sources may be due to the likelihood that some information items are either
very specific (rare) or very general (popular) and/or sometimes highly correlated; this does not necessarily mean
that the sources are dependent but information correlation and distribution have to be analyzed before truth discovery
computation.


\paragraph{Limitations of Truth Discovery Models} 

Most truth discovery models suffer from limiting assumptions on the claims, referred real-world objects, sources, and truth 
discovery results. For example, one important assumption on the claims is that the assertions made by the sources (and whose 
veracity is unknown) are organized into disjoint mutual exclusion sets and exactly one of the claims in each mutual exclusion 
set is assumed to be true. Claims are also assumed to be positive\footnote{\scriptsize{{\it i.e.,}  Cases such  as ``$S$ claims 
that $A$ is false'' or ``$S$ does not claim $A$ is true'' are not considered.}} and  independent, as well as real-world objects 
they refer to. Concerning the sources: a source is supposed to contribute uniformly to all the claims it expresses. Sources are 
assumed to be independent (except in \cite{DongBHS10a}), to make their assertions independently and do not provide conflicting claims.
Moreover, the probability a source asserts a claim is independent of the truth of the claim and there is explicit correspondence 
between the sources and the claims ({\it i.e.,} the models do not consider cases such that ``$S_1$ claims that $S_2$ claims $A$''). Finally,
each claim is assumed to be either true or false. No uncertainty, gradual result or ranking is supported by current models for labeling the 
truthfulness of claims. 

Relaxing these assumptions constitutes a challenging research project that could be overreached by formally defining the semantics of truth 
discovery and making it operational in realistic cases. 

\paragraph*{Cross-Modal Truth Discovery} 
** Laure to complete **

Existing truth discovery studies consider that the information whose veracity must be verified is given 
as textual data by the sources. However, the way information about real-world facts is provided in real 
life can be diverse and various (e.g., video and audio). As a consequence, cross-modal truth discovery 
is becoming an appealing need in the sense that truth discovery has vocation to be more and more required
in real-world applications with multiple facets.
Indeed, data used in many applications are of various nature ranging from unstructured information to movies
and pictures.


\paragraph*{Data Dynamicity in  Truth Discovery} 
** Laure to complete **

\iffalse
\section{Towards An Integrative Solution}
To deal with the open problems highlighted above, we propose an integrative solution for truth discovery.
We detail in this section, the initial development of such solution through the DAFNA system.

\paragraph*{Semantics for Truth Discovery} 

Truth discovery from multi-source data relies on the Open World Assumption with overlapping and conflicting data.
Designing an appropriate data model for truth discovery requires a fine trade-off between tractability and expressiveness. 
The vision of DAFNA is to give a concrete and unified semantics to  truth discovery problem. One principled solution --which 
can: {\it i)} relax most limiting assumptions of previous models, {\it ii)} formally unify existing approaches, and {\it iii)}
support inference-- is to define formal semantics of truth discovery systems in modal logics through axioms and canonical {\it Kripke}
sstructures \cite{GorankoOtto06}. However, reasoning in modal logics can quickly become intractable \cite{Gottlob92}. This applies, in
particular, to information items that include possibility in addition to certainty and impossibility (positive or negative claims). 
can be expressed. 
In this work, we have chosen to define the semantics of a truth discovery system such as it supports fragments of modal logics to allow
negations on claims (which is sufficient to express conflicts) and we introduce a particular {\it Kripke} structure that allows claim 
verification procedure and powerful inferring functionalities (for chaining evidences). Few work in databases have considered modal logics
before: 
Calvanese {\it et al.} \cite{CalvaneseGLLR08} use the modal logic $K45^A_n$ to allow mappings between peers in the presence of conflicts. 
Gatterbauer et al. \cite{GatterbauerBKS09} introduce the notion of {\it belief database} to manage conflicting annotations. In our opinion, 
formal semantics and reasoning based on multi-agent epistemic logic for data integration deserves much more attention than it has received 
so far from the Database community. In DAFNA, our vision is to leverage modal logics for defining in a principled way the semantics of truth 
discovery and reasoning about multi-source conflicting claims. This constitutes a novel, alternative solution to current approaches in data 
fusion and integration. 

\paragraph*{Continuous Truth Discovery, Inference, and Belief Revision }



None of the existing truth discovery models continuously incorporate new evidences, 
new claims, contextual metadata, prior beliefs, and background knowledge in their computation.
They rely on {\it ad hoc} parametrization and do not provide revision, {\it what-if} analysis
or explanation of their results. The vision of DAFNA is to automate claim verification continuously
and adaptively for dynamic environments (e.g., for emergency response or humanitarian scenarios such
as the one illustrated in Section~2). The system continuously searches and finds supporting and opposing 
evidences, as well as contextual meta-information from the Web of Data (B1); it adapts and revises its knowledge
and belief of the sources/claims and recompute the truthfulness of the claims (B4).  
DAFNA is in-line with recent work on continuous cleaning \cite{VCSM14} and belongs to the new family of dynamic data 
quality techniques in database systems. But it is intended to go beyond dynamic data consistency checking since the 
system incorporates contexts, evidences, and error estimates in addition to the set of claims; it supports evidence-based
reasoning and inference with uncertainty and bias estimations and handles, in a scalable way, the complete information processing
pipeline and truth discovery inference.

\paragraph*{Diagnostics and Error Propagation Monitoring}


There is a large body of work on managing uncertain and incomplete information \cite{GreenT06,AgrawalSUW10}. Our work shares a similar 
motivation for information that is not certain. However, we do not only measure, track, evaluate uncertainty (and biases) of user-generated 
contents, but DAFNA system also monitors uncertainty generated by the system itself in the information processing. Errors are estimated at 
each stage of the truth discovery process and incorporated into the final results' computation by the key module (B5) {\it Diagnostics and Error
Propagation} in Figure~1. DAFNA infrastructure supports aggregation of system state and allows the user to specify {\it ad hoc} monitoring tasks 
by using lightweight Event-Condition-Action (ECA) rules applied to each module: information extraction (B1),  data preprocessing and alignment (B2),
data and source quality profiling (B3), and truth discovery  and revision (B4). In that sense,  DAFNA is a diagnostic system that is able to analyze 
information on its performance and accuracy at each stage and can incorporate this information in its results, either for validation, error estimation
or for supporting and documenting clear  explanation and visualization of the results provided to the users by (F1), (F2), and (F3) front-end modules. 
\fi



% Bibliography
\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{references}
                             % Sample .bib file with references that match those in
                             % the 'Specifications Document (V1.5)' as well containing
                             % 'legacy' bibs and bibs with 'alternate codings'.
                             % Gerry Murray - March 2012

% History dates
\received{November 2015}{**** ****}{**** ****}


\medskip

\end{document}
% End of v2-acmsmall-sample.tex (March 2012) - Gerry Murray, ACM


