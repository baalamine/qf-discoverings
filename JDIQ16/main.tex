% v2-acmsmall-sample.tex, dated March 6 2012
% This is a sample file for ACM small trim journals
%
% Compilation using 'acmsmall.cls' - version 1.3 (March 2012), Aptara Inc.
% (c) 2010 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex latex
%
% For tracking purposes => this is v1.3 - March 2012

\documentclass[prodmode,acmtecs]{acmsmall} % Aptara syntax

% Package to generate and customize Algorithm as per ACM style
%\usepackage{mathptm}
\usepackage[pdfborder={0 0 0}]{hyperref}
\usepackage[ruled]{algorithm2e}
\usepackage{csquotes}
\renewcommand{\algorithmcfname}{ALGORITHM}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}

% Metadata Information
\acmVolume{6}
\acmNumber{6}
\acmArticle{6}
\acmYear{2015}
\acmMonth{1}

% Document starts
\begin{document}

% HEADERS
\markboth{L. Berti-Equille and M. L. BA}{Actionable Truth Discovery Challenges}
% TITLE
\title{Actionable Truth Discovery Challenges}
% AUTHORS AND AFFILIATION
\author{LAURE BERTI-EQUILLE, MOUHAMADOU LAMINE BA
\affil{Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar}
}

\category{H.3.3}{Information Storage and Retrieval}{Information Search and Retrieval}
\category{H.2.0}{Database Management}{General}
\terms{Algorithms, Management, Verification}
\keywords{Truth Discovery, Fact-checking, Data Quality, Data Fusion, Information Extraction}
\acmformat{Laure Berti-Equille, Mouhamadou Lamine Ba,  2015. Actionable Truth Discovery Challenges.}


\begin{bottomstuff}
Author's address: L. Berti-Equille, M. L. Ba, Qatar Computing Research Institute(Current address), Hamad
Bin Khalifa University, Tornado Tower 18th, P.O. Box 5825, Doha, Qatar.
\end{bottomstuff}

\maketitle


\section{Introduction}
As online user-generated content grows exponentially, the reliance on Web data and information from social 
networking is growing in many domains for various private and corporate usages. 
One of the fundamental difficulties is that data can be biased, noisy, outdated, incorrect, misleading and
thus unreliable. Massive data from multiple sources amplifies this problem since conflicting information
have to be \textquote{aligned}, compared  and check to estimate their veracity. Obviously, truth discovery from 
the Web has significant practical importance: online rumor propagation~\cite{rumor-icdm2013}, mis- or disinformation
can have tremendous impacts on our society, economy, politics, and homeland security\footnote{\scriptsize{\url{http://www.dtic.mil/dtic/tr/fulltext/u2/a552461.pdf}}}. 
Online fact-checkers (e.g., FactCheck\footnote{\scriptsize{\url{www.factcheck.org/}}}) and humanitarian initiatives~\cite{ImranECDM13}
(e.g., AIDR\footnote{\scriptsize{\url{http://aidr.qcri.org/}}}) have rapidly emerged as unavoidable for classifying and verifying 
(semi-automatically) online information. Beyond social media and computational journalism, the truth discovery issue, intellectually 
and technically interesting enough, has been also widely studied in both the artificial intelligence and the database communities,
sometimes under the names of  \textquote{fact-checking}~\cite{GoasdoueKKLMZ13}, \textquote{information trustworthiness}~\cite{Thirunarayan2014182},
\textquote{information credibility}~\cite{PasternackR13} or \textquote{information corroboration}~\cite{GallandAMS10}. 



Given a set of assertions from multiple sources, the ultimate goal of truth discovery is to label the claimed
data items as true or false and compute sources' reliability with no \emph{a-priori} knowledge about the 
truthfulness of the assertions and the sources. One major line of previous work relaxed such a assumption and extended 
fact-finding models with prior knowledge either about the assertions~\cite{PasternackR13} or about the source 
reputation via trust assessment~\cite{BalakrishnanK11}. Another line of research aimed at iteratively computing 
and updating the trustworthiness of a source as a function of the belief in its claims, and then the belief score 
of each claim as a function of the trustworthiness its sources~\cite{YinHY08}. In this line, several probabilistic
models have been proposed to incorporate various aspects beyond source trustworthiness and claim belief, namely, source
dependence~\cite{DongBHS10a}, temporality in discovering evolving truth~\cite{DongBS09a}, hardness of certain claims~\cite{GallandAMS10}, 
accounting for complex data structures~\cite{ZhaoRGH12,GoasdoueKKLMZ13}.
Current approaches, however, are still limited in scope and also suffer from substantial drawbacks; restrictive 
assumptions in the models, opacity, complex model parametrization, and lack of scalability make them hard to use 
to the wide diversity of information available on the Web and for realistic scenarios where knowing the truth as soon as possible is critical. 




 We argue that the next-generation data-sharing systems need to manage not only heterogeneity but also conflicting and false 
 information  coming from various channels, in different languages, formats, and at different paces. Truth discovery systems  have to be designed to help institutions and citizens with providing rigorous, scientific explanations and reports 
 of their findings along with collected evidences. % (that can have a potential value in court similarly to data forensics outcomes). 
  Although some preliminary work have addressed parts of this vision, e.g., \cite{DongS2013,DongBHS10a,LiDLMS12}, we argue that there is a need for a more fundamental paradigm shift in data management  to address the truth discovery problem natively. Formally, this goes beyond adding layers and extensions to data fusion heuristics, data provenance or truth discovery models. Technically, the challenges are not only to  design techniques and prototypes of truth discovery systems but also to democratize operational tools for Web scale {\it information  triage} and veracity verification.
  
  
  
  
%In this paper, we present a set of research chaleenges that together
%aim to effectively address the problem of truth discovery in real-world over-information scenarios. 
%We describe the challenges we face, propose our vision of a preliminary solution, and lay down a research agenda that goes beyond the Database community.


 
%\vspace{-0.1cm}
% ****************** ARCHITECTURE ****************************************
\section{Actionable Truth Discovery Challenges}~\label{sect:challenges-solutions}
%\vspace{-0.2cm}
%To achieve this vision, our goal is to design a truth discovery system to extract information from multi-channel sources in different languages.
We present in this section a set of actionable open problems related to truth discovery. We start by an illustrative
example showing the need to deal with in priority these questions.
\paragraph*{ An Illustrative Example}


``The first casualty when war comes, is truth,'' said American Senator Hiram Johnson in 1917. 
For reporters, photographers, and cameramen captured the realities of wars and armed conflicts, sound 
and verifiable data is extremely difficult to gather and determining the complete picture of what 
occurred during a conflict is hard and perilous. Data is generally used effectively to answer a specific 
question (e.g., how many civilian casualties in Syria?) but it is often stretched to answer a broader question
for which it was not suited, blurring the lines between ``what was observable'' and  ``what was true''. In this context, 
sources of information can include victims or witness reports  and online volunteered information (e.g., in English or Arabic) 
from personal and institutional Web pages, social and traditional media, NGOs', governmental and administrative records\footnote{\scriptsize{e.g., \url{http://www.correlatesofwar.org/}}}. 
Seeking the truth is a tedious process manually done by war correspondents, United Nations experts and commissioners, Truth 
Commissions\footnote{\scriptsize{\url{ http://www.truthcommission.org/}}}, human rights activists, journalists, and historians (e.g., WITNESS\footnote{\scriptsize{\url{http://www.witness.org}}}, StoryFul\footnote{\scriptsize{\url{http://storyful.com/}}}). 
For this type of application, automating continuous truth discovery from the Web and social media networks to support decision-making 
and provide timely response to crisis situations goes far beyond data integrity checking, data quality, and data fusion. 




 While the challenges identified hereafter  are by no means exhaustive, they are certainly important issues to address in priority for 
 designing a suitable truth discovery system.


\paragraph*{Timely and Actionable Truth Discovery} 

Discovering truth from past events and historical data is certainly useful and results may be validated more easily since ground truth and full data sets already exist before the time of analysis. However, from a humanitarian perspective, actionable truth discovery from quasi real-time data could save lives. % or help in determining responsibilities from a legal perspective.
In this context, information extraction and triage as well as truth discovery computation need to be streamlined, prioritized,  and adjusted to the degree of emergency and incompleteness of available information. This important usage-driven aspect goes beyond consistency checking and constraints. For example, information such as ``The Chrysler building had an explosion and it affected the Empire State building'' can be automatically verified: these buildings are about 2~km away and hence this information can not be true. However, more often what journalists/emergency responders need, is to verify information such as ``The Chrysler building had an explosion'' when there are very few primary sources claiming it initially. Timely and actionable truth discovery requires the prioritization and adjustment of information checking tasks specifically to the communities that will use the data.
%

\paragraph*{Data Alignment Across Languages, Formats, and Channels} 


Agility of a truth discovery system is of utmost importance both at the technical, structural, and semantic levels. Agility is defined as the ability of the system to efficiently extract and map information: {\it i)} from various languages, {\it ii)} in various formats and data structures, and {\it iii)} supported by various media and technologies. Traditional information extraction pipelines  require several analysis stages ranging from text preprocessing %(e.g., split the input text into sentences, tokenize the sentences, lemmatize the tokens, tag their part-of-speech, etc.)
 to entity resolution and normalization.  
For each content, once entities, attributes, and relations are recognized and extracted, statements are identified, and sentences are classified (e.g., forecast or not), they have to be linked across multiple contents in different languages and eventually translated into a common language (e.g., English). A number of applications have been deployed\footnote{\scriptsize{For example, Europe Media Monitor's News Explorer (\url{http://emm.newsexplorer.eu}) gathers news, clusters related news stories, and extracts names, locations, general person-person relations, and event types; Open-Calais from Thomson Reuters (\url{http://www.opencalais.com}) extracts a range of entity, relation, and event types from general and business news.}} for information extraction, but most of them have used hand-crafted lists of terms and regular expressions, rather than corpus-trained approaches. They are usually specific to a single channel/application/language and cannot be considered ``agile'' enough for extracting, gathering and 
aligning information from various languages, formats or channels.  Moreover, each stage of textual content analysis (from preprocessing, entity matching to classification) produces systematic and random errors that need to be considered in truth discovery computation. None of the very few attempts  to couple these applications to truth discovery systems (e.g., \cite{GoasdoueKKLMZ13}) has considered the uncertainty from information extraction and processing affecting the truth discovery results. Tracing and estimating the errors of information extraction, formatting, and linking  is one of the main challenges for automating truth discovery. 
%These aspects have been somehow disconnected and underexploited in previous research.


\paragraph*{Incomplete and Biased Observations}  


Observation data may be incomplete and biased for various reasons: 
some information sources may not give all their data for security or privacy concerns; 
some sources have format limitations; when the sources do not explicitly provide temporal 
or spatial information, the time and location values are missing and need to be inferred.
Typically, the Open World assumption holds since  not all the real-world entities/events 
may have been observed and reported by the sources. Online sources have  various levels 
of {\it a priori} knowledge on how the observation data have been collected. In many cases,
opportunistic (or volunteered) data are {\it biased by  observation effort} and the underlying
observation method is unknown. It is thus important to explore how one can retrieve and quantify
the observation effort from modeling the data provider's/observers' distribution. Data  can be biased
in many other ways. For example, data can be affected by a {\it selection bias} that is the extent to
which a piece of information is claimed by a category of individuals who are likely to have access to 
and choose to use a certain type of media or channel\footnote{\scriptsize{e.g., social media users are
usually younger, technologically savvy, motivated individuals versus individuals who are older, more remote,
lacking access or ability or motivation to use technology and whose stories/observations are likely missing 
from this channel. }}. Data may also suffer from the {\it observer's bias} (related to the individual's ability
to accurately remember and describe events) and {\it disclosure bias} (related to witness's incentive  (or disincentive) 
to  include certain events or details). One challenge is to estimate the incompleteness and biases and take them into account
in the truth discovery computation.

\paragraph*{Decontextualization and Distortion}  

When a piece of information  is extracted from its original 
content and channel, it may lose its context along with important 
``semantic markers'' to understand {\it when, where, how, why,} and
{\it for which purpose/audience} this particular piece of information 
has been produced, what it is supposed to mean in the absolute sense and
also relatively to its particular context and  information channel (e.g., a tweet in a thread).
Information without context can be easily distorted and misinterpreted. For example, ascertaining
the veracity of a controversial information that has been re-tweeted many times in different contexts
by various users with different emotions and motivations is difficult without the description of these
contexts. Moreover, the pace has to be considered when information  updates from Twitter, Facebook, and 
Wikipedia have to be ``aligned'' with considering the source granularity ({\it i.e.}, a source can be an
individual, an organization, a company, a government, etc.). Much research work has studied the formalization 
of contexts and rich context representations have been proposed \cite{eps270829}. However, current information 
extraction  methods constrain the context representation and can usually not handle a wide, unpredictable 
range of topics. Ultimately, all meta-information about the context and sources' characteristics have to be encoded 
as evidences and analyzed for truth discovery computation.

\paragraph*{Source Expertise and Information Correlation} 

In many domains, some sources are more authoritative or specialized, providing
accurate information for a small subset of real-world objects, while other
sources are generalist with a wider coverage, providing a huge amount of information,
some of which may be out-of-date or imprecise. Determining truth between such sources
based only on majority voting and similarity of values can easily lead to erroneous conclusions.
Hence, any approach for determining truth needs to consider the possibility that sources have different 
levels of expertise, various updating policies, and they provide different coverages of information over time.
Moreover, similar values across many sources may be due to the likelihood that some information items are either
very specific (rare) or very general (popular) and/or sometimes highly correlated; this does not necessarily mean
that the sources are dependent but information correlation and distribution have to be analyzed before truth discovery
computation.


\paragraph{Limitations of Truth Discovery Models} 

Most truth discovery models suffer from limiting assumptions on the claims, referred real-world objects, sources, and truth 
discovery results. For example, one important assumption on the claims is that the assertions made by the sources (and whose 
veracity is unknown) are organized into disjoint mutual exclusion sets and exactly one of the claims in each mutual exclusion 
set is assumed to be true. Claims are also assumed to be positive\footnote{\scriptsize{{\it i.e.,}  Cases such  as ``$S$ claims 
that $A$ is false'' or ``$S$ does not claim $A$ is true'' are not considered.}} and  independent, as well as real-world objects 
they refer to. Concerning the sources: a source is supposed to contribute uniformly to all the claims it expresses. Sources are 
assumed to be independent (except in \cite{DongBHS10a}), to make their assertions independently and do not provide conflicting claims.
Moreover, the probability a source asserts a claim is independent of the truth of the claim and there is explicit correspondence 
between the sources and the claims ({\it i.e.,} the models do not consider cases such that ``$S_1$ claims that $S_2$ claims $A$''). Finally,
each claim is assumed to be either true or false. No uncertainty, gradual result or ranking is supported by current models for labeling the 
truthfulness of claims. 

Relaxing these assumptions constitutes a challenging research project that could be overreached by formally defining the semantics of truth 
discovery and making it operational in realistic cases. 

\paragraph*{Cross-Modal Truth Discovery} 
** Laure to complete **

Existing truth discovery studies consider that the information whose veracity must be verified is given 
as textual data by the sources. However, the way information about real-world facts is provided in real 
life can be diverse and various (e.g., video and audio). As a consequence, cross-modal truth discovery 
is becoming an appealing need in the sense that truth discovery has vocation to be more and more required
in real-world applications with multiple facets.
Indeed, data used in many applications are of various nature ranging from unstructured information to movies
and pictures.


\paragraph*{Data Dynamicity in  Truth Discovery} 
** Laure to complete **

\section{Towards An Integrative Solution}
To deal with the open problems highlighted above, we propose an integrative solution for truth discovery.
We detail in this section, the initial development of such solution through the DAFNA system.

\paragraph*{Semantics for Truth Discovery} 

Truth discovery from multi-source data relies on the Open World Assumption with overlapping and conflicting data.
Designing an appropriate data model for truth discovery requires a fine trade-off between tractability and expressiveness. 
The vision of DAFNA is to give a concrete and unified semantics to  truth discovery problem. One principled solution --which 
can: {\it i)} relax most limiting assumptions of previous models, {\it ii)} formally unify existing approaches, and {\it iii)}
support inference-- is to define formal semantics of truth discovery systems in modal logics through axioms and canonical {\it Kripke}
sstructures \cite{GorankoOtto06}. However, reasoning in modal logics can quickly become intractable \cite{Gottlob92}. This applies, in
particular, to information items that include possibility in addition to certainty and impossibility (positive or negative claims). 
can be expressed. 
In this work, we have chosen to define the semantics of a truth discovery system such as it supports fragments of modal logics to allow
negations on claims (which is sufficient to express conflicts) and we introduce a particular {\it Kripke} structure that allows claim 
verification procedure and powerful inferring functionalities (for chaining evidences). Few work in databases have considered modal logics
before: 
Calvanese {\it et al.} \cite{CalvaneseGLLR08} use the modal logic $K45^A_n$ to allow mappings between peers in the presence of conflicts. 
Gatterbauer et al. \cite{GatterbauerBKS09} introduce the notion of {\it belief database} to manage conflicting annotations. In our opinion, 
formal semantics and reasoning based on multi-agent epistemic logic for data integration deserves much more attention than it has received 
so far from the Database community. In DAFNA, our vision is to leverage modal logics for defining in a principled way the semantics of truth 
discovery and reasoning about multi-source conflicting claims. This constitutes a novel, alternative solution to current approaches in data 
fusion and integration. 

\paragraph*{Continuous Truth Discovery, Inference, and Belief Revision }



None of the existing truth discovery models continuously incorporate new evidences, 
new claims, contextual metadata, prior beliefs, and background knowledge in their computation.
They rely on {\it ad hoc} parametrization and do not provide revision, {\it what-if} analysis
or explanation of their results. The vision of DAFNA is to automate claim verification continuously
and adaptively for dynamic environments (e.g., for emergency response or humanitarian scenarios such
as the one illustrated in Section~2). The system continuously searches and finds supporting and opposing 
evidences, as well as contextual meta-information from the Web of Data (B1); it adapts and revises its knowledge
and belief of the sources/claims and recompute the truthfulness of the claims (B4).  
DAFNA is in-line with recent work on continuous cleaning \cite{VCSM14} and belongs to the new family of dynamic data 
quality techniques in database systems. But it is intended to go beyond dynamic data consistency checking since the 
system incorporates contexts, evidences, and error estimates in addition to the set of claims; it supports evidence-based
reasoning and inference with uncertainty and bias estimations and handles, in a scalable way, the complete information processing
pipeline and truth discovery inference.

\paragraph*{Diagnostics and Error Propagation Monitoring}


There is a large body of work on managing uncertain and incomplete information \cite{GreenT06,AgrawalSUW10}. Our work shares a similar 
motivation for information that is not certain. However, we do not only measure, track, evaluate uncertainty (and biases) of user-generated 
contents, but DAFNA system also monitors uncertainty generated by the system itself in the information processing. Errors are estimated at 
each stage of the truth discovery process and incorporated into the final results' computation by the key module (B5) {\it Diagnostics and Error
Propagation} in Figure~1. DAFNA infrastructure supports aggregation of system state and allows the user to specify {\it ad hoc} monitoring tasks 
by using lightweight Event-Condition-Action (ECA) rules applied to each module: information extraction (B1),  data preprocessing and alignment (B2),
data and source quality profiling (B3), and truth discovery  and revision (B4). In that sense,  DAFNA is a diagnostic system that is able to analyze 
information on its performance and accuracy at each stage and can incorporate this information in its results, either for validation, error estimation
or for supporting and documenting clear  explanation and visualization of the results provided to the users by (F1), (F2), and (F3) front-end modules. 




% Bibliography
\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{references}
                             % Sample .bib file with references that match those in
                             % the 'Specifications Document (V1.5)' as well containing
                             % 'legacy' bibs and bibs with 'alternate codings'.
                             % Gerry Murray - March 2012

% History dates
\received{November 2015}{**** ****}{**** ****}


\medskip

\end{document}
% End of v2-acmsmall-sample.tex (March 2012) - Gerry Murray, ACM


